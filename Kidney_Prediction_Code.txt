import warnings
warnings.filterwarnings("ignore")
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import seaborn as sns
df = pd.read_csv('kidney_disease.csv')
df.head()
df.shapedf.isnull().sum()
# Impuing Null values
from sklearn.impute import SimpleImputer
imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
df_imputed=pd.DataFrame(imp_mode.fit_transform(df))
df_imputed.columns=df.columns
df_imputed
df_imputed.isnull().sum()
# Finding Unique values in the columns
for i in df_imputed.columns:
print("*************************************************",i,"************************
************************************")
print()
print(set(df_imputed[i].tolist()))
print()
print(df_imputed["rc"].mode())
print(df_imputed["wc"].mode())
print(df_imputed["pcv"].mode())
df_imputed["classification"]
df_imputed["classification"]=df_imputed["classification"].apply(lambda x:'ckd' if x=="ckd\t" else x)
df_imputed["cad"]=df_imputed["cad"].apply(lambda x:'no' if x=="\tno" else x)
df_imputed["dm"]=df_imputed["dm"].apply(lambda x:'no' if x=="\tno" else x)
df_imputed["dm"]=df_imputed["dm"].apply(lambda x:'yes' if x=="\tyes" else x)
df_imputed["dm"]=df_imputed["dm"].apply(lambda x:'yes' if x==' yes' else x)
df_imputed["rc"]=df_imputed["rc"].apply(lambda x:'5.2' if x=='\t?' else x)
df_imputed["wc"]=df_imputed["wc"].apply(lambda x:'9800' if x=='\t6200' else x)
df_imputed["wc"]=df_imputed["wc"].apply(lambda x:'9800' if x=='\t8400' else x)
df_imputed["wc"]=df_imputed["wc"].apply(lambda x:'9800' if x== '\t?' else x)
df_imputed["pcv"]=df_imputed["pcv"].apply(lambda x:'41' if x=='\t43' else x)
df_imputed["pcv"]=df_imputed["pcv"].apply(lambda x:'41' if x== '\t?' else x)
# Finding Unique values in the columns
for i in df_imputed.columns:
print("*************************************************",i,"************************
************************************")
print()
print(set(df_imputed[i].tolist()))
print()
#Check Label Imbalance
import matplotlib.pyplot as plt
import seaborn as sns
temp=df_imputed["classification"].value_counts()
temp_df= pd.DataFrame({'classification': temp.index,'values': temp.values})
print(sns.barplot(x = 'classification', y="values", data=temp_df))
df.dtypes
# fixing data types
df_imputed.dtypes
for i in df.select_dtypes(exclude=["object"]).columns:
df_imputed[i]=df_imputed[i].apply(lambda x: float(x))
df_imputed.dtypes
sns.pairplot(df_imputed)
# Find and remove outliers of data
def boxplots(col):
sns.boxplot(df[col])
plt.show()
for i in list(df_imputed.select_dtypes(exclude=["object"]).columns)[1:]:
boxplots(i)
# Find the distribution of data
def distplots(col):
sns.distplot(df[col])
plt.show()
for i in list(df_imputed.select_dtypes(exclude=["object"]).columns)[1:]:
distplots(i)
# Label encoding to convert categorical values to numerical
from sklearn import preprocessing
df_enco=df_imputed.apply(preprocessing.LabelEncoder().fit_transform)
df_enco
# Finding Correlations
import matplotlib.pyplot as plt
plt.figure(figsize=(20,20))
corr=df_enco.corr()
sns.heatmap(corr,annot=True)

